{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from model import Resnet\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import resnet_from_model\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import split_data\n",
    "# import torch\n",
    "# test_cifar_data = torch.ones(2, 3, 32, 32)\n",
    "# x_a, x_b = split_data(test_cifar_data, 'cifar10')\n",
    "# print(x_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_id = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "test_data = torch.ones(2, 3, 64, 64)\n",
    "client, server = Resnet(level=level_id)\n",
    "output = client(test_data)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = output\n",
    "print(decoder_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import cifar_discriminator_model, resnet_discriminator\n",
    "d = resnet_discriminator(decoder_input.shape[1], level=level_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_output = d(output)\n",
    "print(d_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model import resent_decoder\n",
    "# d_input_shape = output.shape[1:]\n",
    "# decoder = resent_decoder(d_input_shape, level=level_id)\n",
    "# decoder_output = decoder(decoder_input)\n",
    "# print(decoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########分界线#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Resnet\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import copy\n",
    "from vfl import VFLNN, Client, Server\n",
    "from utils import split_data\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root='./data/tiny-imagenet-200/train', \n",
    "                                                         transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                          tiny_normalize])\n",
    "                                                         )\n",
    "test_dataset = torchvision.datasets.ImageFolder(root='./data/tiny-imagenet-200/val', \n",
    "                                                        transform= transforms.Compose([transforms.ToTensor(),\n",
    "                                                            tiny_normalize])\n",
    "                                                        )\n",
    "auix_dataset = torchvision.datasets.ImageFolder(root='./data/tiny-imagenet-200/test',\n",
    "                                                        transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                            tiny_normalize])\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(auix_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6965, -0.7137, -0.6794,  ..., -0.1657, -0.1999, -0.1999],\n",
      "         [-0.6965, -0.6965, -0.6623,  ..., -0.1486, -0.1828, -0.1999],\n",
      "         [-0.6794, -0.6794, -0.6452,  ..., -0.1314, -0.1486, -0.1657],\n",
      "         ...,\n",
      "         [-0.5253, -0.5082, -0.4911,  ..., -0.2171, -0.2513, -0.2684],\n",
      "         [-0.5253, -0.5082, -0.4911,  ..., -0.1999, -0.2171, -0.2513],\n",
      "         [-0.5253, -0.5253, -0.4911,  ..., -0.1828, -0.1828, -0.1999]],\n",
      "\n",
      "        [[-0.4951, -0.5126, -0.5301,  ..., -0.0399, -0.0749, -0.0749],\n",
      "         [-0.4951, -0.4951, -0.5126,  ..., -0.0224, -0.0574, -0.0749],\n",
      "         [-0.4776, -0.4776, -0.4951,  ..., -0.0049, -0.0224, -0.0399],\n",
      "         ...,\n",
      "         [-0.4076, -0.3901, -0.3725,  ..., -0.0924, -0.1275, -0.1450],\n",
      "         [-0.4076, -0.3901, -0.3725,  ..., -0.0749, -0.0924, -0.1275],\n",
      "         [-0.4076, -0.4076, -0.3725,  ..., -0.0574, -0.0574, -0.0749]],\n",
      "\n",
      "        [[-0.3753, -0.3927, -0.3578,  ...,  0.1825,  0.1476,  0.1476],\n",
      "         [-0.3753, -0.3753, -0.3404,  ...,  0.1999,  0.1651,  0.1476],\n",
      "         [-0.3578, -0.3578, -0.3230,  ...,  0.2173,  0.1999,  0.1825],\n",
      "         ...,\n",
      "         [-0.2184, -0.2010, -0.1835,  ...,  0.0953,  0.0605,  0.0431],\n",
      "         [-0.2184, -0.2010, -0.1835,  ...,  0.1128,  0.0953,  0.0605],\n",
      "         [-0.2184, -0.2184, -0.1835,  ...,  0.1302,  0.1302,  0.1128]]])\n"
     ]
    }
   ],
   "source": [
    "print(auix_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_model1, top_model = Resnet(level=2)\n",
    "bottom_model2 = copy.deepcopy(bottom_model1)\n",
    "bottom_model1, bottom_model2, top_model = bottom_model1.to(device), bottom_model2.to(device), top_model.to(device)\n",
    "client1 = Client(bottom_model1)\n",
    "client2 = Client(bottom_model2)\n",
    "server = Server(top_model, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Train Loss:  4.445169939422607\n",
      "----------------------------Test-----------------------------\n",
      "Accuracy of the network on the test images: 13.60%\n",
      "Epoch:  1\n",
      "Train Loss:  3.95451335647583\n",
      "----------------------------Test-----------------------------\n",
      "Accuracy of the network on the test images: 17.00%\n",
      "Epoch:  2\n",
      "Train Loss:  3.752119650115967\n",
      "----------------------------Test-----------------------------\n",
      "Accuracy of the network on the test images: 18.87%\n",
      "Epoch:  3\n",
      "Train Loss:  3.6003039573669433\n",
      "----------------------------Test-----------------------------\n",
      "Accuracy of the network on the test images: 18.85%\n",
      "Epoch:  4\n",
      "Train Loss:  3.448853010635376\n",
      "----------------------------Test-----------------------------\n",
      "Accuracy of the network on the test images: 19.04%\n",
      "Epoch:  5\n",
      "Train Loss:  3.3007006911468504\n",
      "----------------------------Test-----------------------------\n",
      "Accuracy of the network on the test images: 19.33%\n",
      "Epoch:  6\n",
      "Train Loss:  3.1335455814361572\n",
      "----------------------------Test-----------------------------\n",
      "Accuracy of the network on the test images: 18.29%\n",
      "Epoch:  7\n",
      "Train Loss:  2.9598557665252687\n",
      "----------------------------Test-----------------------------\n",
      "Accuracy of the network on the test images: 18.48%\n",
      "Epoch:  8\n",
      "Train Loss:  2.773525110626221\n",
      "----------------------------Test-----------------------------\n",
      "Accuracy of the network on the test images: 18.46%\n",
      "Epoch:  9\n",
      "Train Loss:  2.5951541236114504\n",
      "----------------------------Test-----------------------------\n",
      "Accuracy of the network on the test images: 17.36%\n"
     ]
    }
   ],
   "source": [
    "client_optimizer = torch.optim.Adam(bottom_model1.parameters(), lr=0.001)\n",
    "client2_optimizer = torch.optim.Adam(bottom_model2.parameters(), lr=0.001)\n",
    "server_optimizer = torch.optim.Adam(top_model.parameters(), lr=0.001)\n",
    "client_optimizer = [client_optimizer, client2_optimizer]\n",
    "tar_vflnn = VFLNN(client1, client2, server, client_optimizer, server_optimizer)\n",
    "for epoch in range(10):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    tar_vflnn.train()\n",
    "    train_loss = 0\n",
    "    for i , (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        tar_vflnn.zero_grads()\n",
    "        x_a, x_b = split_data(data, 'tinyImagnet')\n",
    "\n",
    "        vfl_ouput = tar_vflnn(x_a, x_b)\n",
    "        vfl_loss = F.cross_entropy(vfl_ouput, target)\n",
    "        vfl_loss.backward()\n",
    "\n",
    "        tar_vflnn.backward()\n",
    "\n",
    "        tar_vflnn.step()\n",
    "        train_loss += vfl_loss.item() * data.size(0)\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    print(\"Train Loss: \", train_loss)\n",
    "\n",
    "    tar_vflnn.eval()\n",
    "\n",
    "    print(\"----------------------------Test-----------------------------\")\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for test_data, test_target in test_loader:\n",
    "            test_data, test_target = test_data.to(device), test_target.to(device)\n",
    "            x_a, x_b = split_data(test_data, 'tinyImagnet')\n",
    "            outputs = tar_vflnn(x_a, x_b)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += test_target.size(0)\n",
    "            correct += (predicted == test_target).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the network on the test images: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
