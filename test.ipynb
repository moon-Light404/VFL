{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from model import cifar_mobilenet, cifar_discriminator_model, cifar_decoder, cifar_pseudo, vgg16\n",
    "from model1 import BottomModelForCifar10, TopModelForCifar10\n",
    "from vfl import VFLNN, Client, Server\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "b = torch.tensor([4, 5, 6], dtype=torch.float32)\n",
    "loss = F.mse_loss(a,b)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    id = 'cuda:'+ '0'\n",
    "    device = torch.device(id)\n",
    "    torch.cuda.set_device(id)\n",
    "    # cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3407)\n",
    "random.seed(3407)\n",
    "np.random.seed(3407)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    x_a = data[:, :, :, 0:16]\n",
    "    x_b = data[:, :, :, 16:32]\n",
    "    return x_a, x_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "cinic_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "            ])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train = True, transform=cinic_transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train = False, transform=cinic_transform, download=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers = 4, pin_memory = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers = 4, pin_memory = True)\n",
    "\n",
    "target_bottom1,target_top = cifar_mobilenet(level=2)\n",
    "target_bottom2 = copy.deepcopy(target_bottom1)\n",
    "\n",
    "# 模型放到GPU上\n",
    "target_bottom1, target_bottom2, target_top = target_bottom1.to(device), target_bottom2.to(device), target_top.to(device)\n",
    "target_client1 = Client(target_bottom1)\n",
    "target_client2 = Client(target_bottom2)\n",
    "target_server = Server(target_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_iterator = iter(train_dataloader)\n",
    "target_data, target_labels = next(target_iterator)\n",
    "target_data, target_labels = target_data.to(device), target_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 16])\n",
      "[DECODER] activation:  None\n",
      "torch.Size([64, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "x_a, x_b = split_data(target_data) # torch.Size([64, 3, 32, 16])\n",
    "# print(x_a.shape)\n",
    "# target_bottom1_intermediate = target_client1.forward(x_a)\n",
    "# target_bottom2_intermediate = target_client2.forward(x_b)\n",
    "# inter1 = target_bottom1_intermediate.detach()\n",
    "# print(inter1.shape)  # torch.Size([64, 64, 16, 8])  ---> 合并为[64, 64, 16, 16]\n",
    "\n",
    "# pseudo_model, _ = vgg16(level=2, batch_norm = True)\n",
    "# pseudo_model = pseudo_model.to(device)\n",
    "# pseudo_model_ouput = pseudo_model(x_a)\n",
    "\n",
    "# x_a和x_b的shape\n",
    "# torch.Size([64, 3, 32, 16])\n",
    "# torch.Size([64, 3, 32, 16])\n",
    "\n",
    "# print(pseudo_model_ouput.shape)\n",
    "test_out_put1 = target_bottom1(x_a)\n",
    "test_out_put2 = target_bottom2(x_b)\n",
    "discriminator_input_shape = test_out_put1.shape[1:]\n",
    "print(x_a.shape)\n",
    "# decoder\n",
    "decoder = cifar_decoder(discriminator_input_shape, 2, 3)\n",
    "decoder = decoder.to(device)\n",
    "x_a_recvoer = decoder(torch.cat((test_out_put1, test_out_put2), 3))\n",
    "print(x_a_recvoer.shape)\n",
    "\n",
    "# 鉴别器\n",
    "# discriminator = cifar_discriminator_model(discriminator_input_shape, 2)\n",
    "# discriminator = discriminator.to(device)\n",
    "# adv_target_logits = discriminator(test_out_put)\n",
    "# print(adv_target_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 16, 8])\n"
     ]
    }
   ],
   "source": [
    "print(target_bottom1(x_a).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert the tensor to a numpy array and transpose the dimensions\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplots_adjust(wspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, hspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m.05\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert the tensor to a numpy array and transpose the dimensions\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(1, 10, figsize=(20, 2))\n",
    "# plt.subplots_adjust(wspace=0, hspace=-.05)\n",
    "# for i in range(10):\n",
    "#     image = target_data[i].cpu().numpy().transpose((1, 2, 0))\n",
    "#     image = image * 0.5 + 0.5 # Unnormalize the image\n",
    "#     axes[i].imshow(image)\n",
    "#     axes[i].axis('off')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 16, 16])\n",
      "torch.Size([2, 10])\n",
      "tensor([[-0.0262,  0.0297,  0.0209, -0.0080,  0.0303,  0.0173, -0.0062, -0.0299,\n",
      "         -0.0277,  0.0249],\n",
      "        [-0.0262,  0.0297,  0.0209, -0.0080,  0.0303,  0.0173, -0.0062, -0.0299,\n",
      "         -0.0277,  0.0249]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dataset_shape = train_dataset[0][0].shape\n",
    "test_data = torch.ones(2,dataset_shape[0], dataset_shape[1], dataset_shape[2]).to(device)\n",
    "aa = target_bottom1(test_data)\n",
    "bb = target_top(aa)\n",
    "print(aa.shape)\n",
    "print(bb.shape)\n",
    "print(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 16, 8])\n"
     ]
    }
   ],
   "source": [
    "client1_optimizer = optim.Adam(target_bottom1.parameters(), lr=0.01)\n",
    "client2_optimizer = optim.Adam(target_bottom2.parameters(), lr=0.01)\n",
    "server_optimizer = optim.Adam(target_top.parameters(), lr=0.01)\n",
    "client_optimizer = [client1_optimizer, client2_optimizer]\n",
    "target_vflNN = VFLNN(target_client1, target_client2, target_server, client_optimizer, server_optimizer)\n",
    "\n",
    "# test_out_put = target_vflNN.client2(x_a)\n",
    "# print(test_out_put.shape)\n",
    "\n",
    "\n",
    "for i in range(30):\n",
    "    print(\"Epoch: \", i) \n",
    "    target_vflNN.train()\n",
    "    train_loss = 0\n",
    "    for batchidx, (data, target) in enumerate(train_dataloader):\n",
    "        \n",
    "        data, target_label = data.to(device), target.to(device)\n",
    "        target_vflNN.zero_grads()\n",
    "        x_a, x_b = split_data(data)\n",
    "\n",
    "        target_vflNN_output = target_vflNN(x_a, x_b)\n",
    "        # 计算loss\n",
    "        target_vflNN_loss = F.cross_entropy(target_vflNN_output, target_label)\n",
    "        \n",
    "        # 反向传播\n",
    "        target_vflNN_loss.backward()\n",
    "        # 整体vflNN的反向传播\n",
    "        target_vflNN.backward()\n",
    "\n",
    "        train_loss += target_vflNN_loss.item() * data.size(0)\n",
    "        # 更新模型\n",
    "        target_vflNN.step()\n",
    "    train_loss = train_loss / len(train_dataloader.dataset)\n",
    "    print(\"======loss=======\")\n",
    "    print(train_loss)\n",
    "        \n",
    "    target_vflNN.eval()\n",
    "    \n",
    "    print(\"---------------------------testtesttest---------------------------\")\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for test_data, test_target in test_dataloader:\n",
    "            test_data, test_target = test_data.to(device), test_target.to(device)\n",
    "            x_a, x_b = split_data(test_data)\n",
    "            outputs = target_vflNN(x_a, x_b)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += test_target.size(0)\n",
    "            correct += (predicted == test_target).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the network on the test images: {accuracy:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
