{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Resnet\n",
    "level_id = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import split_data\n",
    "# import torch\n",
    "# test_cifar_data = torch.ones(2, 3, 32, 32)\n",
    "# x_a, x_b = split_data(test_cifar_data, 'cifar10')\n",
    "# print(x_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = torch.ones(2, 3, 64, 64)\n",
    "# client, server = Resnet(level=level_id)\n",
    "# output = client(test_data)\n",
    "# print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_input = output\n",
    "# print(decoder_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model import cifar_discriminator_model, resnet_discriminator\n",
    "# d = resnet_discriminator(decoder_input.shape[1], level=level_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_output = d(output)\n",
    "# print(d_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model import resent_decoder\n",
    "# d_input_shape = output.shape[1:]\n",
    "# decoder = resent_decoder(d_input_shape, level=level_id)\n",
    "# decoder_output = decoder(decoder_input)\n",
    "# print(decoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########分界线#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Resnet\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import copy\n",
    "from vfl import VFLNN, Client, Server\n",
    "from utils import split_data\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root='./data/tiny-imagenet-200/train', \n",
    "                                                         transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                          tiny_normalize])\n",
    "                                                         )\n",
    "test_dataset = torchvision.datasets.ImageFolder(root='./data/tiny-imagenet-200/val', \n",
    "                                                        transform= transforms.Compose([transforms.ToTensor(),\n",
    "                                                            tiny_normalize])\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_model1, top_model = Resnet(level=2)\n",
    "bottom_model2 = copy.deepcopy(bottom_model1)\n",
    "bottom_model1, bottom_model2, top_model = bottom_model1.to(device), bottom_model2.to(device), top_model.to(device)\n",
    "client1 = Client(bottom_model1)\n",
    "client2 = Client(bottom_model2)\n",
    "server = Server(top_model, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m vfl_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(vfl_ouput, target)\n\u001b[0;32m     17\u001b[0m vfl_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 19\u001b[0m \u001b[43mtar_vflnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m tar_vflnn\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     22\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m vfl_loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mf:\\python_code\\VFL\\vfl.py:91\u001b[0m, in \u001b[0;36mVFLNN.backward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     89\u001b[0m grad_to_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mserver_backward()\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Backpropagate the gradients to the clients\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_to_client\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient2\u001b[38;5;241m.\u001b[39mclient_backward(grad_to_client[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mf:\\python_code\\VFL\\vfl.py:24\u001b[0m, in \u001b[0;36mClient.client_backward\u001b[1;34m(self, grad_from_server)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03mThis function is used to backpropagate the gradients from the server to the client model\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_from_server \u001b[38;5;241m=\u001b[39m grad_from_server\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_side_intermediate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_from_server\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anconda\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client_optimizer = torch.optim.Adam(bottom_model1.parameters(), lr=0.001)\n",
    "client2_optimizer = torch.optim.Adam(bottom_model2.parameters(), lr=0.001)\n",
    "server_optimizer = torch.optim.Adam(top_model.parameters(), lr=0.001)\n",
    "client_optimizer = [client_optimizer, client2_optimizer]\n",
    "tar_vflnn = VFLNN(client1, client2, server, client_optimizer, server_optimizer)\n",
    "for epoch in range(90):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    tar_vflnn.train()\n",
    "    train_loss = 0\n",
    "    for i , (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        tar_vflnn.zero_grads()\n",
    "        x_a, x_b = split_data(data, 'tinyImagnet')\n",
    "\n",
    "        vfl_ouput = tar_vflnn(x_a, x_b)\n",
    "        vfl_loss = F.cross_entropy(vfl_ouput, target)\n",
    "        vfl_loss.backward()\n",
    "\n",
    "        tar_vflnn.backward()\n",
    "\n",
    "        tar_vflnn.step()\n",
    "        train_loss += vfl_loss.item() * data.size(0)\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    print(\"Train Loss: \", train_loss)\n",
    "\n",
    "    tar_vflnn.eval()\n",
    "\n",
    "    print(\"----------------------------Test-----------------------------\")\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for test_data, test_target in test_loader:\n",
    "            test_data, test_target = test_data.to(device), test_target.to(device)\n",
    "            x_a, x_b = split_data(test_data, 'tinyImagnet')\n",
    "            outputs = tar_vflnn(x_a, x_b)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += test_target.size(0)\n",
    "            correct += (predicted == test_target).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the network on the test images: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
